{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom matplotlib import pyplot as plt\nimport os\nimport math","execution_count":1,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***Pre-Processing the dataset***"},{"metadata":{"trusted":true},"cell_type":"code","source":"'''Pulling the photos from folders with their paths'''\n\npath_0 = []\ntrain_path_0 = \"../input/hand-sign-language-digit-dataset-for-0-5/0/\"                #zero\nfor path in os.listdir(train_path_0):\n    if '.JPG' in path:\n        path_0.append(os.path.join(train_path_0, path))\n        \npath_1 = []\ntrain_path_1 = \"../input/hand-sign-language-digit-dataset-for-0-5/1/\"                #one\nfor path in os.listdir(train_path_1):\n    if '.JPG' in path:\n        path_1.append(os.path.join(train_path_1, path))\n        \npath_2 = []\ntrain_path_2 = \"../input/hand-sign-language-digit-dataset-for-0-5/2/\"                #two\nfor path in os.listdir(train_path_2):\n    if '.JPG' in path:\n        path_2.append(os.path.join(train_path_2, path))\n        \npath_3 = []\ntrain_path_3 = \"../input/hand-sign-language-digit-dataset-for-0-5/3/\"                #three\nfor path in os.listdir(train_path_3):\n    if '.JPG' in path:\n        path_3.append(os.path.join(train_path_3, path))\n        \npath_4 = []\ntrain_path_4 = \"../input/hand-sign-language-digit-dataset-for-0-5/4/\"                #four\nfor path in os.listdir(train_path_4):\n    if '.JPG' in path:\n        path_4.append(os.path.join(train_path_4, path))\n        \npath_5 = []\ntrain_path_5 = \"../input/hand-sign-language-digit-dataset-for-0-5/5/\"                #five\nfor path in os.listdir(train_path_5):\n    if '.JPG' in path:\n        path_5.append(os.path.join(train_path_5, path))\n\nlen(path_0), len(path_1), len(path_2), len(path_3), len(path_4), len(path_5)","execution_count":2,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"(205, 206, 206, 206, 207, 207)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''Load training set'''\n\n'''total pics in training set =  1237\n    training_set = 1110 --- 185 for each digit\n    validation_set = 120 --- 20 for each digit'''\n\ntrain_set_orig = np.zeros((1110, 64, 64, 3), dtype='float32')\nfor i in range(185):                                                                #loading \"zero\"\n    image = Image.open(path_0[i])\n    img_resized = image.resize((64,64))\n    train_set_orig[i] = np.asarray(img_resized)\n\nfor i in range(185, 370):                                                           #loading \"one\"\n    image = Image.open(path_1[i - 185])\n    img_resized = image.resize((64,64))\n    train_set_orig[i] = np.asarray(img_resized)\n        \nfor i in range(370, 555):                                                           #loading \"two\"\n    image = Image.open(path_2[i - 370])\n    img_resized = image.resize((64,64))\n    train_set_orig[i] = np.asarray(img_resized)\n        \nfor i in range(555, 740):                                                           #loading \"three\"\n    image = Image.open(path_3[i - 555])\n    img_resized = image.resize((64,64))\n    train_set_orig[i] = np.asarray(img_resized)\n        \nfor i in range(740, 925):                                                           #loading \"four\"\n    image = Image.open(path_4[i - 740])\n    img_resized = image.resize((64,64))\n    train_set_orig[i] = np.asarray(img_resized)\n        \nfor i in range(925, 1110):                                                          #loading \"five\"\n    image = Image.open(path_5[i - 925])\n    img_resized = image.resize((64,64))\n    train_set_orig[i] = np.asarray(img_resized)\n","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''Load validation set'''\n\nval_set_orig = np.zeros((120, 64, 64, 3), dtype='float32')\nfor i in range(20):                                                                 #loading \"zero\"\n    image = Image.open(path_0[i + 185])\n    img_resized = image.resize((64,64))\n    val_set_orig[i] = np.asarray(img_resized)\n    \nfor i in range(20, 40):                                                             #loading \"one\"\n    image = Image.open(path_1[i + 165])\n    img_resized = image.resize((64,64))\n    val_set_orig[i] = np.asarray(img_resized)\n    \nfor i in range(40, 60):                                                             #loading \"two\"\n    image = Image.open(path_2[i + 145])\n    img_resized = image.resize((64,64))\n    val_set_orig[i] = np.asarray(img_resized)\n    \nfor i in range(60, 80):                                                             #loading \"three\"\n    image = Image.open(path_3[i + 125])\n    img_resized = image.resize((64,64))\n    val_set_orig[i] = np.asarray(img_resized)\n\nfor i in range(80, 100):                                                            #loading \"four\"\n    image = Image.open(path_4[i + 105])\n    img_resized = image.resize((64,64))\n    val_set_orig[i] = np.asarray(img_resized)\n    \nfor i in range(100, 120):                                                           #loading \"five\"\n    image = Image.open(path_5[i + 85])\n    img_resized = image.resize((64,64))\n    val_set_orig[i] = np.asarray(img_resized)","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''Labelling the training set having 6-dimensional vector of o's and 1's with 1 where index = digit and zero otherwise'''\n\ntrain_y_ = np.zeros((1110, 6))\nfor i in range(185):                                                               #labelling \"zero\"\n    train_y_[i, 0] = 1\n\nfor i in range(185, 370):                                                          #labelling \"one\"\n    train_y_[i, 1] = 1\n        \nfor i in range(370, 555):                                                          #labelling \"two\"\n    train_y_[i, 2] = 1\n        \nfor i in range(555, 740):                                                          #labelling \"three\"\n    train_y_[i, 3] = 1\n    \nfor i in range(740, 925):                                                          #labelling \"four\"\n    train_y_[i, 4] = 1\n        \nfor i in range(925, 1110):                                                         #labelling \"five\"\n    train_y_[i, 5] = 1\n","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''Labelling the validation set having 6-dimensional vector of o's and 1's with 1 where index = digit and zero otherwise'''\n\nval_y_ = np.zeros((120, 6))\nfor i in range(20):                                                                 #labelling \"zero\"\n    val_y_[i, 0] = 1\n\nfor i in range(20, 40):                                                             #labelling \"one\"\n    val_y_[i, 1] = 1\n        \nfor i in range(40, 60):                                                             #labelling \"two\"\n    val_y_[i, 2] = 1\n        \nfor i in range(60, 80):                                                             #labelling \"three\"\n    val_y_[i, 3] = 1\n        \nfor i in range(80, 100):                                                            #labelling \"four\"\n    val_y_[i, 4] = 1\n        \nfor i in range(100, 120):                                                           #labelling \"five\"\n    val_y_[i, 5] = 1\n","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"''''Suffling training set pics'''\n\nnp.random.seed(0)\nm_train = train_set_orig.shape[0]\npermutation = list(np.random.permutation(m_train))\ntrain_set_x = train_set_orig[permutation, :]\ntrain_y = train_y_[permutation, :].T\n\n''''Suffling validation set pics'''\n\nnp.random.seed(1)\nm_val = val_set_orig.shape[0]\npermutation = list(np.random.permutation(m_val))\nval_set_x = val_set_orig[permutation, :]\nval_y = train_y_[permutation, :].T","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''Example of an image'''\n\nindex = 100\nplt.imshow(np.uint8(train_set_x[index]), interpolation='nearest')\nplt.show()\nprint(train_y[:, index])","execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"stream","text":"[0. 1. 0. 0. 0. 0.]\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"***Summary of Processed data***"},{"metadata":{"trusted":true},"cell_type":"code","source":"m_train = train_set_x.shape[0]\nm_val = val_set_x.shape[0]\nnum_px = train_set_x.shape[1]\n\nprint (\"Number of training examples: m_train = \" + str(m_train))\nprint (\"Number of validation examples: m_val = \" + str(m_val))\nprint (\"Height/Width of each image: num_px = \" + str(num_px))\nprint (\"Each image is of size: (\" + str(num_px) + \", \" + str(num_px) + \", 3)\")\nprint (\"train_set_x shape: \" + str(train_set_x.shape))\nprint (\"train_set_y shape: \" + str(train_y.shape))\nprint (\"val_set_x shape: \" + str(val_set_x.shape))\nprint (\"val_set_y shape: \" + str(val_y.shape))","execution_count":9,"outputs":[{"output_type":"stream","text":"Number of training examples: m_train = 1110\nNumber of validation examples: m_val = 120\nHeight/Width of each image: num_px = 64\nEach image is of size: (64, 64, 3)\ntrain_set_x shape: (1110, 64, 64, 3)\ntrain_set_y shape: (6, 1110)\nval_set_x shape: (120, 64, 64, 3)\nval_set_y shape: (6, 120)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"***Flattening the training and validation arrays***"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x = train_set_x.reshape(1110,-1).T\nval_x = val_set_x.reshape(120,-1).T\n\nprint (\"train_set_x_flatten shape: \" + str(train_x.shape))\nprint (\"train_set_y shape: \" + str(train_y.shape))\nprint (\"val_set_x_flatten shape: \" + str(val_x.shape))\nprint (\"val_set_y shape: \" + str(val_y.shape))","execution_count":10,"outputs":[{"output_type":"stream","text":"train_set_x_flatten shape: (12288, 1110)\ntrain_set_y shape: (6, 1110)\nval_set_x_flatten shape: (12288, 120)\nval_set_y shape: (6, 120)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''Standardizing dataset'''\n\ntrain_x = train_x /255\nval_x = val_x/255","execution_count":11,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***Model For Sign language Prediction***"},{"metadata":{"trusted":true},"cell_type":"code","source":"def sigmoid(z):\n    \n    '''Compute the sigmoid of z\n    Arguments:\n    z -- A scalar or numpy array of any size.\n    Return:\n    s -- sigmoid(z)'''\n    \n    s = 1/(1 + np.exp(-z))\n    \n    return s, z","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def softmax(z):\n    \n    '''Compute the softmax of z\n    Arguments:\n    z -- A scalar or numpy array of any size.\n    Return:\n    s -- softmax(z)'''\n    \n    s = np.exp(z) / np.sum(np.exp(z), axis=0)\n    \n    return s, z","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def initialize_parameters(layer_dims):\n    \n    \"\"\"Arguments:\n    layer_dims -- python array (list) containing the dimensions of each layer in our network\n    Returns:\n    parameters -- python dictionary containing your parameters \"W1\", \"b1\", ..., \"WL\",\"bL\":\n    Wl -- weight matrix of shape (layer_dims[l], layer_dims[l-1])\n    bl -- bias vector of shape (layer_dims[l], 1)\"\"\"\n    \n    np.random.seed(3)\n    parameters = {}\n    L = len(layer_dims)                                                                              #number of layers in the network\n    for l in range(1, L):\n        parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l-1])*0.01\n        parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n        \n    assert(parameters['W' + str(l)].shape == (layer_dims[l], layer_dims[l-1]))\n    assert(parameters['b' + str(l)].shape == (layer_dims[l], 1))\n    \n    return parameters","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def linear_forward(A, W, b):\n    \n    \"\"\"Implement the linear part of a layer's forward propagation.\n    Arguments:\n    A -- activations from previous layer (or input data): (size of previous layer, number of examples)\n    W -- weights matrix: numpy array of shape (size of current layer, size of previouslayer)\n    b -- bias vector, numpy array of shape (size of the current layer, 1)\n    Returns:\n    Z -- the input of the activation function, also called pre-activation parameter\n    cache -- a python tuple containing \"A\", \"W\" and \"b\" ; stored for computing the backward pass efficiently\"\"\"\n    \n    Z = np.dot(W, A) + b\n    \n    assert(Z.shape == (W.shape[0], A.shape[1]))\n    \n    cache = (A, W, b)\n    \n    return Z, cache","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def linear_activation_forward(A_prev, W, b, activation):\n    \n    \"\"\"Implement the forward propagation for the LINEAR->ACTIVATION layer\n    Arguments:\n    A_prev -- activations from previous layer (or input data): (size of previous layer, number of examples)\n    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)\n    b -- bias vector, numpy array of shape (size of the current layer, 1)\n    activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"softmax\"\n    Returns:\n    A -- the output of the activation function, also called the post-activation value\n    cache -- a python tuple containing \"linear_cache\" and \"activation_cache\"; stored for computing the backward pass efficiently\"\"\"\n    \n    if activation == \"sigmoid\":\n        Z, linear_cache = linear_forward(A_prev, W, b)\n        A, activation_cache = sigmoid(Z)\n    else:\n        Z, linear_cache = linear_forward(A_prev, W, b)\n        A, activation_cache = softmax(Z)\n        \n    assert (A.shape == (W.shape[0], A_prev.shape[1]))\n    \n    cache = (linear_cache, activation_cache)\n    \n    return A, cache","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def forward_propagation(X, parameters):\n    \n    \"\"\"Implement forward propagation for the [LINEAR->SIGMOID]*(L-1)->LINEAR->SOFTMAX computation\n    Arguments:\n    X -- data, numpy array of shape (input size, number of examples)\n    parameters -- output of initialize_parameters_deep()\n    Returns:\n    AL -- last post-activation value\n    caches -- list of caches containing: every cache of linear_activation_forward() (there are L-1 of them, indexed from 0 to L-1)\"\"\"\n    \n    caches = []\n    A = X\n    L = len(parameters) // 2                                                             #number of layers in the neural network\n    \n    #Implement [LINEAR -> SIGMOID]*(L-1). Add \"cache\" to the \"caches\" list.\n    \n    for l in range(1, L):\n        A_prev = A\n        A, cache = linear_activation_forward(A_prev, parameters['W' + str(l)], parameters['b' + str(l)], activation = \"sigmoid\")\n        caches.append(cache)\n    AL, cache = linear_activation_forward(A, parameters['W' + str(L)], parameters['b' + str(L)], activation = \"softmax\")\n    caches.append(cache)\n    \n    assert(AL.shape == (6,X.shape[1]))\n    \n    return AL, caches","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def compute_cost(AL, Y):\n    \n    \"\"\"Implement the cost function.\n    Arguments:\n    AL -- probability vector corresponding to your label predictions, shape (6, number of examples)\n    Y -- true \"label\" vector, shape (6, number of examples)\n    Returns:\n    cost -- cross-entropy cost\"\"\"\n    \n    m = Y.shape[1]\n    cost = -np.sum(Y * np.log(AL) + (1 - Y) * np.log(1 - AL))/m\n    cost = np.squeeze(cost)\n    \n    assert(cost.shape == ())\n    \n    return cost","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def linear_backward(dZ, cache):\n    \n    \"\"\"Implement the linear portion of backward propagation for a single layer (layer l)\n    Arguments:\n    dZ -- Gradient of the cost with respect to the linear output (of current layer l)\n    cache -- tuple of values (A_prev, W, b) coming from the forward propagation in the current layer\n    Returns:\n    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n    dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n    db -- Gradient of the cost with respect to b (current layer l), same shape as b\"\"\"\n    \n    A_prev, W, b = cache\n    m = A_prev.shape[1]\n    dW = np.dot(dZ, A_prev.T)/m\n    db = np.sum(dZ, axis = 1, keepdims = True)/m\n    dA_prev = np.dot(W.T, dZ)\n    \n    assert (dA_prev.shape == A_prev.shape)\n    assert (dW.shape == W.shape)\n    assert (db.shape == b.shape)\n    \n    return dA_prev, dW, db","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def sigmoid_backward(dA, Z):\n    \n    '''Implements the backward propagation for SIGMOID unit. \n    Arguments:\n    dA -- post-activation gradient for current layer l\n    Z -- activation cache for current layer l\n    Returns:\n    dZ -- dA ∗ g′(Z), g(.) is the sigmoid function'''\n    \n    A, activation_cache = sigmoid(Z)\n    dZ = dA * (A * (1 - A))\n    \n    return dZ","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def linear_activation_backward(dA, cache):\n    \n    \"\"\"Implement the backward propagation for the LINEAR->ACTIVATION layer.\n    Arguments:\n    dA -- post-activation gradient for current layer l\n    cache -- tuple of values (linear_cache, activation_cache) we store for computing backward propagation efficiently\n    Returns:\n    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n    dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n    db -- Gradient of the cost with respect to b (current layer l), same shape as b\"\"\"\n    \n    linear_cache, activation_cache = cache\n    dZ = sigmoid_backward(dA, activation_cache)\n    dA_prev, dW, db = linear_backward(dZ, linear_cache)\n    \n    return dA_prev, dW, db","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def backward_propagation(AL, Y, caches):\n    \n    \"\"\"Implement the backward propagation for the [LINEAR->SIGMOID] * (L-1) -> LINEAR -> SOFTMAX group\n    Arguments:\n    AL -- probability vector, output of the forward propagation (L_model_forward())\n    Y -- true \"label\" vector\n    caches -- list of caches containing: every cache of linear_activation_forward() with \"sigmoid\" (it's caches[l],\n    for l in range(L-1) i.e l = 0...L-2) the cache of linear_activation_forward() with \"softmax\" (it's caches[L-1])\n    Returns:\n    grads -- A dictionary with the gradients\n    grads[\"dA\" + str(l)] = ...\n    grads[\"dW\" + str(l)] = ...\n    grads[\"db\" + str(l)] = ...\"\"\"\n    \n    grads = {}\n    L = len(caches)                                                                        #number of layers\n    m = AL.shape[1]\n    Y = Y.reshape(AL.shape)                                                                #after this line, Y is the same shape as AL\n    \n    #Initializing the backpropagation\n    \n    dZL = AL - Y\n    \n    current_cache = caches[L-1]\n    linear_cache, activation_cache = caches[L - 1]\n    A_prev, W, b = linear_cache\n    grads[\"dW\" + str(L)] = np.dot(dZL, A_prev.T)/m\n    grads[\"db\" + str(L)] = np.sum(dZL, axis = 1, keepdims = True)/m\n    grads[\"dA\" + str(L-1)] = np.dot(W.T, dZL)\n    \n    for l in reversed(range(L - 1)):                                                       # lth layer: (SIGMOID -> LINEAR) gradients.\n        current_cache = caches[l]\n        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA\" + str(l + 1)], current_cache)\n        grads[\"dA\" + str(l)] = dA_prev_temp\n        grads[\"dW\" + str(l + 1)] = dW_temp\n        grads[\"db\" + str(l + 1)] = db_temp\n        \n    return grads","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def random_mini_batches(X, Y, mini_batch_size, seed = 0):\n    \n    '''Creates a list of random minibatches from (X, Y)\n    Arguments:\n    X -- input data, of shape (number of examples, input size)\n    Y -- true \"label\" vector (1 for cat / 0 for dog), of shape (number of examples, 1)\n    mini_batch_size -- size of the mini-batches, integer\n    Returns:\n    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)'''\n    \n    np.random.seed(seed)            \n    m = X.shape[1]                                                          #number of training examples\n    mini_batches = []\n        \n    #Shuffle (X, Y)\n    \n    permutation = list(np.random.permutation(m))\n    shuffled_X = X[:, permutation]\n    shuffled_Y = Y[:, permutation]\n\n    #Partition (shuffled_X, shuffled_Y). Minus the end case.\n    \n    num_complete_minibatches = math.floor(m/mini_batch_size)                #number of mini batches of size mini_batch_size in your partitionning\n    \n    for k in range(0, num_complete_minibatches):\n        mini_batch_X = shuffled_X[:, k*mini_batch_size:(k+1)*mini_batch_size]\n        mini_batch_Y = shuffled_Y[:, k*mini_batch_size:(k+1)*mini_batch_size]\n        mini_batch = (mini_batch_X, mini_batch_Y)\n        mini_batches.append(mini_batch)\n    \n    #Handling the end case (last mini-batch < mini_batch_size)\n    \n    if m % mini_batch_size != 0:\n        mini_batch_X = shuffled_X[:, mini_batch_size * num_complete_minibatches::]\n        mini_batch_Y = shuffled_Y[:, mini_batch_size * num_complete_minibatches::]\n        mini_batch = (mini_batch_X, mini_batch_Y)\n        mini_batches.append(mini_batch)\n    \n    return mini_batches","execution_count":23,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def initialize_adam(parameters) :\n    \n    \"\"\"Initializes v and s as two python dictionaries with:\n    - keys: \"dW1\", \"db1\", ..., \"dWL\", \"dbL\" \n    - values: numpy arrays of zeros of the same shape as the corresponding gradients/parameters.\n    Arguments:\n    parameters -- python dictionary containing your parameters.\n                  parameters[\"W\" + str(l)] = Wl\n                  parameters[\"b\" + str(l)] = bl\n    Returns: \n    v -- python dictionary that will contain the exponentially weighted average of the gradient.\n                    v[\"dW\" + str(l)] = ...\n                    v[\"db\" + str(l)] = ...\n    s -- python dictionary that will contain the exponentially weighted average of the squared gradient.\n                    s[\"dW\" + str(l)] = ...\n                    s[\"db\" + str(l)] = ...\"\"\"\n    \n    L = len(parameters) // 2                                                  #number of layers in the neural networks\n    v = {}\n    s = {}\n    \n    for l in range(L):\n        v[\"dW\" + str(l+1)] = np.zeros((parameters[\"W\" + str(l+1)].shape))\n        v[\"db\" + str(l+1)] = np.zeros((parameters[\"b\" + str(l+1)].shape))\n        s[\"dW\" + str(l+1)] = np.zeros((parameters[\"W\" + str(l+1)].shape))\n        s[\"db\" + str(l+1)] = np.zeros((parameters[\"b\" + str(l+1)].shape))\n        \n    return v, s","execution_count":24,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def update_parameters_with_adam(parameters, grads, v, s, t, learning_rate = 0, beta1 = 0.9, beta2 = 0.999,  epsilon = 1e-8):\n    \n    \"\"\"Update parameters using Adam\n    Arguments:\n    parameters -- python dictionary containing your parameters:\n                  parameters['W' + str(l)] = Wl\n                  parameters['b' + str(l)] = bl\n    grads -- python dictionary containing your gradients for each parameters:\n             grads['dW' + str(l)] = dWl\n             grads['db' + str(l)] = dbl\n    v -- Adam variable, moving average of the first gradient, python dictionary\n    s -- Adam variable, moving average of the squared gradient, python dictionary\n    learning_rate -- the learning rate, scalar.\n    beta1 -- Exponential decay hyperparameter for the first moment estimates \n    beta2 -- Exponential decay hyperparameter for the second moment estimates \n    epsilon -- hyperparameter preventing division by zero in Adam updates\n    Returns:\n    parameters -- python dictionary containing your updated parameters \n    v -- Adam variable, moving average of the first gradient, python dictionary\n    s -- Adam variable, moving average of the squared gradient, python dictionary\"\"\"\n    \n    L = len(parameters) // 2                                                          #number of layers in the neural networks\n    v_corrected = {}                                                                  #Initializing first moment estimate, python dictionary\n    s_corrected = {}                                                                  #Initializing second moment estimate, python dictionary\n    \n    for l in range(L):\n        #Moving average of the gradients.\n        \n        v[\"dW\" + str(l+1)] = beta1*v['dW' + str(l+1)] + (1 - beta1)*grads['dW' + str(l+1)]\n        v[\"db\" + str(l+1)] = beta1*v['db' + str(l+1)] + (1 - beta1)*grads['db' + str(l+1)]\n\n        #Compute bias-corrected first moment estimate.\n        \n        v_corrected[\"dW\" + str(l+1)] = v[\"dW\" + str(l+1)]/(1 - beta1**t)\n        v_corrected[\"db\" + str(l+1)] = v[\"db\" + str(l+1)]/(1 - beta1**t)\n\n        #Moving average of the squared gradients.\n        \n        s[\"dW\" + str(l+1)] = beta2*s[\"dW\" + str(l+1)] + (1 - beta2)*(grads['dW' + str(l+1)]**2)\n        s[\"db\" + str(l+1)] = beta2*s[\"db\" + str(l+1)] + (1 - beta2)*(grads['db' + str(l+1)]**2)\n\n        #Compute bias-corrected second raw moment estimate.\n        \n        s_corrected[\"dW\" + str(l+1)] = s[\"dW\" + str(l+1)]/(1 - beta2**t)\n        s_corrected[\"db\" + str(l+1)] = s[\"db\" + str(l+1)]/(1 - beta2**t)\n\n        #Update parameters.\n        \n        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)] - learning_rate*(v_corrected[\"dW\" + str(l+1)])/(np.sqrt(s_corrected[\"dW\" + str(l+1)]) + epsilon)\n        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - learning_rate*(v_corrected[\"db\" + str(l+1)])/(np.sqrt(s_corrected[\"db\" + str(l+1)]) + epsilon)\n\n    return parameters, v, s","execution_count":25,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict(Y):\n    \n    '''Predict whether the labels using learned parameters (w, b)\n    Arguments:\n    Y -- a numpy array (vector) containing true labels\n    Returns:\n    Y_prediction -- a numpy array (vector) containing all predictions'''\n    \n    m = Y.shape[1]\n    Y_prediction = np.zeros(Y.shape)\n\n    for i in range(m):\n        c = np.where(Y[:, i] == np.amax(Y[:, i]))\n        Y_prediction[c[0], i] = 1\n        \n    return Y_prediction","execution_count":26,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def model(X, Y, X_val, Y_val, layers_dims, learning_rate = 0.01, mini_batch_size = 32, beta1 = 0.9, beta2 = 0.999, epsilon = 1e-8, num_epochs = 10000, print_cost = True):\n    \n    \"\"\"L-layer neural network model which can be run in adam optimizer modes.\n    Arguments:\n    X -- data, numpy array of shape (input size, number of examples)\n    Y -- true \"label\" vector, of shape (6, number of examples)\n    X_val -- test set represented by a numpy array of shape (m_test, num_px * num_px * 3)\n    Y_val -- test labels represented by a numpy array (vector) of shape (m_test, 6)\n    layers_dims -- python list, containing the size of each layer\n    learning_rate -- the learning rate\n    mini_batch_size -- the size of a mini batch\n    beta1 -- Exponential decay hyperparameter for the past gradients estimates \n    beta2 -- Exponential decay hyperparameter for the past squared gradients estimates \n    epsilon -- hyperparameter preventing division by zero in Adam updates\n    num_epochs -- number of epochs\n    print_cost -- True to print the cost every 50 epochs\n    Returns:\n    d -- dictionary containing information about the model.\"\"\"\n\n    d = {}\n    L = len(layers_dims)                                        #number of layers in the neural networks\n    costs = []                                                  #to keep track of the cost\n    t = 0                                                       #initializing the counter required for Adam update\n    seed = 10                                                   #For grading purposes, so that your \"random\" minibatches are the same as ours\n    \n    #Initialize parameters\n    \n    parameters = initialize_parameters(layers_dims)\n    \n    v, s = initialize_adam(parameters)\n    \n    #Optimization loop\n    \n    for i in range(num_epochs):\n        \n        #Define the random minibatches. We increment the seed to reshuffle differently the dataset after each epoch\n        \n        seed = seed + 1\n        minibatches = random_mini_batches(X, Y, mini_batch_size, seed)\n        m = len(minibatches)\n        cost_total = 0\n        \n        for minibatch in minibatches:\n\n            #Select a minibatch\n            \n            (minibatch_X, minibatch_Y) = minibatch\n\n            #Forward propagation\n            \n            AL, caches = forward_propagation(minibatch_X, parameters)\n\n            #Compute cost and add to the cost total\n            \n            cost_total += compute_cost(AL, minibatch_Y)\n\n            #Backward propagation\n            \n            grads = backward_propagation(AL, minibatch_Y, caches)\n\n            #Update parameters\n            \n            t = t + 1                                                                                  #Adam counter\n            parameters, v, s = update_parameters_with_adam(parameters, grads, v, s, t, learning_rate, beta1, beta2,  epsilon)\n        cost_avg = cost_total / m\n        \n        #Print the cost every 100 epoch\n        \n        if print_cost and i % 50 == 0:\n            print (\"Cost after epoch %i: %f\" %(i, cost_avg))\n        if print_cost and i % 50 == 0:\n            costs.append(cost_avg)\n            \n    AL_train, c1 = forward_propagation(X, parameters)\n    AL_val, c2 = forward_propagation(X_val, parameters)\n    Y_prediction_val = predict(AL_val)\n    Y_prediction_train = predict(AL_train)\n    \n    print(\"train set accuracy for model: {} %\".format(100 - np.mean(np.abs(Y_prediction_train - Y)) * 100))\n    print(\"validation set accuracy for model: {} %\".format(100 - np.mean(np.abs(Y_prediction_val - Y_val)) * 100))\n                \n    d = {\"costs\": costs,\n         \"Y_prediction_val\": Y_prediction_val,\n         \"Y_prediction_train\" : Y_prediction_train,\n         \"parameters\": parameters,\n         \"learning_rate\": learning_rate,\n         \"num_epochs\": num_epochs}\n    \n    return d","execution_count":27,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"layers_dims = [12288, 24, 12, 6]\nd = model(train_x, train_y, val_x, val_y, layers_dims, learning_rate = 0.0001, mini_batch_size = 32, beta1 = 0.9, beta2 = 0.999,  epsilon = 1e-8, num_epochs = 500, print_cost = True)","execution_count":28,"outputs":[{"output_type":"stream","text":"Cost after epoch 0: 2.703662\nCost after epoch 50: 2.413085\nCost after epoch 100: 2.132620\nCost after epoch 150: 1.930738\nCost after epoch 200: 1.775847\nCost after epoch 250: 1.665910\nCost after epoch 300: 1.575757\nCost after epoch 350: 1.447649\nCost after epoch 400: 1.299552\nCost after epoch 450: 1.092606\ntrain set accuracy for model: 98.52852852852853 %\nvalidation set accuracy for model: 72.22222222222223 %\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"***Learning Curve***"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(d[\"costs\"], c=\"r\", linewidth=1)\nplt.ylabel('cost', fontsize=14)\nplt.xlabel(\"number of epochs (per 50)\", fontsize=14)\nplt.title(\"Learning rate = \" + str(d[\"learning_rate\"]))\nplt.grid()","execution_count":29,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}